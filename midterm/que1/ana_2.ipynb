{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################################################################################################################################\n",
    "#                     Mid Term: Author-Vaishali Lambe, NUID-001286444                         #\n",
    "################################################################################################################################\n",
    "\n",
    "# Question 1:\n",
    "\n",
    "**Analysis 2**\n",
    "#### Who were the people with the most emails?\n",
    "################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin/midterm/data/enron/maildir\n",
      "C:\\Users\\Admin/midterm/data/enron/preprocessed_analysis2.json\n",
      "Preprocessed data? True\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the modules we need.\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import SoupStrainer\n",
    "import datetime\n",
    "from glob import glob\n",
    "import json\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import string\n",
    "import sys\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Path to the raw data.\n",
    "raw_data_path = os.path.expanduser(\"~/midterm/data/enron/maildir\")\n",
    "print(raw_data_path)\n",
    "\n",
    "# Path to the preprocessed data file (may or may not exist).\n",
    "preprocessed_data_path = os.path.expanduser(\"~/midterm/data/enron/preprocessed_analysis2.json\")\n",
    "print(preprocessed_data_path)\n",
    "\n",
    "# Check to see if the file is already there.\n",
    "def have_preprocessed_data():\n",
    "    return os.path.isfile(preprocessed_data_path)\n",
    "\n",
    "print(\"Preprocessed data? \" + str(have_preprocessed_data()))\n",
    "    \n",
    "# Make sure the stopwords corpus is available.\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the home directories in the Enron mail dump.\n",
    "def get_enron_home_dirs():\n",
    "    \n",
    "    # Save the working directory (for later restoration).\n",
    "    saved_path = os.getcwd()\n",
    "    print(saved_path)\n",
    "\n",
    "    # Get the paths to the data files.\n",
    "    # Use the contents of the directory as a way to get the usernames.\n",
    "    os.chdir(raw_data_path)\n",
    "    result = glob('*')\n",
    "\n",
    "    # Restore the working directory.\n",
    "    os.chdir(saved_path)\n",
    "    print(os.getcwd())\n",
    "\n",
    "    print(\"found \" + str(len(result)) + \" home directories:\")\n",
    "    print(result[0:50])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many items of email does each user have in their mail directory?\n",
    "\n",
    "# Create the mapping from a user to the number of email items they have.\n",
    "def create_user_email_list():\n",
    "    result = []\n",
    "\n",
    "    enron_home_dirs = get_enron_home_dirs()\n",
    "    for u in enron_home_dirs:\n",
    "        home_path = os.path.join(raw_data_path, u)\n",
    "        #print(home_path)\n",
    "    \n",
    "        # Save the current working directory.\n",
    "        saved_wd = os.getcwd()\n",
    "    \n",
    "        os.chdir(home_path)\n",
    "        user_emails = glob(\"**/**\")\n",
    "        result.append({'user': u, 'emails': len(user_emails)})\n",
    "    \n",
    "        #print(\"{user} had {count} emails\".format(user = u, count = len(user_emails)))\n",
    "    \n",
    "        # Restore the current working directory.\n",
    "        os.chdir(saved_wd)\n",
    "    \n",
    "    return result\n",
    "    \n",
    "# Restore from a preprocessed file.\n",
    "def restore_user_email_list():\n",
    "    print(\"Restoring from: \" + preprocessed_data_path)\n",
    "\n",
    "    result = []\n",
    "    with open(preprocessed_data_path, 'rt') as f:\n",
    "        try:\n",
    "            result = json.load(f)\n",
    "        except ValueError:\n",
    "            result = []\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Save data as a preprocessed file.\n",
    "def save_user_email_list(list_to_save):\n",
    "    print(\"Saving user email list to: \" + preprocessed_data_path)\n",
    "    with open(preprocessed_data_path, 'wt') as f:\n",
    "        json.dump(list_to_save, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring from: C:\\Users\\Admin/midterm/data/enron/preprocessed_analysis2.json\n",
      "[{'user': 'dasovich-j', 'emails': 56457}, {'user': 'kaminski-v', 'emails': 53355}, {'user': 'mann-k', 'emails': 46762}, {'user': 'jones-t', 'emails': 39900}, {'user': 'shackleton-s', 'emails': 37374}, {'user': 'kean-s', 'emails': 32764}, {'user': 'farmer-d', 'emails': 25850}, {'user': 'taylor-m', 'emails': 24230}, {'user': 'germany-c', 'emails': 23941}, {'user': 'beck-s', 'emails': 23261}, {'user': 'nemec-g', 'emails': 21310}, {'user': 'symes-k', 'emails': 19485}, {'user': 'scott-s', 'emails': 16044}, {'user': 'rogers-b', 'emails': 16018}, {'user': 'bass-e', 'emails': 15633}, {'user': 'sanders-r', 'emails': 14531}, {'user': 'campbell-l', 'emails': 12979}, {'user': 'guzman-m', 'emails': 12108}, {'user': 'shapiro-r', 'emails': 12100}, {'user': 'lay-k', 'emails': 11874}]\n"
     ]
    }
   ],
   "source": [
    "# Does the preprocessed file exist?\n",
    "user_email_list = []\n",
    "if have_preprocessed_data():\n",
    "    user_email_list = restore_user_email_list()\n",
    "else:\n",
    "    user_email_list = create_user_email_list()\n",
    "    save_user_email_list(user_email_list)\n",
    "\n",
    "# Sort in descending order so the most prolific emailers are at the top.\n",
    "user_email_list.sort(key=lambda x: x['emails'], reverse=True)\n",
    "print(user_email_list[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 50 users with the most emails:\n",
      "===================================================================================\n",
      "dasovich-j had 56457 emails\n",
      "kaminski-v had 53355 emails\n",
      "mann-k had 46762 emails\n",
      "jones-t had 39900 emails\n",
      "shackleton-s had 37374 emails\n",
      "kean-s had 32764 emails\n",
      "farmer-d had 25850 emails\n",
      "taylor-m had 24230 emails\n",
      "germany-c had 23941 emails\n",
      "beck-s had 23261 emails\n",
      "nemec-g had 21310 emails\n",
      "symes-k had 19485 emails\n",
      "scott-s had 16044 emails\n",
      "rogers-b had 16018 emails\n",
      "bass-e had 15633 emails\n",
      "sanders-r had 14531 emails\n",
      "campbell-l had 12979 emails\n",
      "guzman-m had 12108 emails\n",
      "shapiro-r had 12100 emails\n",
      "lay-k had 11874 emails\n",
      "lenhart-m had 11840 emails\n",
      "lokay-m had 11134 emails\n",
      "haedicke-m had 10481 emails\n",
      "sager-e had 10385 emails\n",
      "love-p had 10004 emails\n",
      "arnold-j had 9796 emails\n",
      "fossum-d had 9592 emails\n",
      "perlingiere-d had 9556 emails\n",
      "lavorato-j had 9370 emails\n",
      "mcconnell-m had 8895 emails\n",
      "giron-d had 8440 emails\n",
      "skilling-j had 8259 emails\n",
      "shankman-j had 7679 emails\n",
      "hain-m had 7640 emails\n",
      "delainey-d had 7132 emails\n",
      "williams-w3 had 6880 emails\n",
      "whalley-l had 6670 emails\n",
      "neal-s had 6536 emails\n",
      "white-s had 6531 emails\n",
      "hernandez-j had 6432 emails\n",
      "steffes-j had 6364 emails\n",
      "blair-l had 6192 emails\n",
      "mclaughlin-e had 6169 emails\n",
      "allen-p had 6068 emails\n",
      "stclair-c had 6060 emails\n",
      "watson-k had 5900 emails\n",
      "cash-m had 5852 emails\n",
      "griffith-j had 5658 emails\n",
      "linder-e had 5610 emails\n",
      "rodrique-r had 5532 emails\n"
     ]
    }
   ],
   "source": [
    "# Pretty-print the 50 users with the most emails.\n",
    "print(\"\\nThe 50 users with the most emails:\")\n",
    "print(\"===================================================================================\")\n",
    "for i in user_email_list[0:50]:\n",
    "    print(\"{name} had {count} emails\".format(name=i['user'], count=i['emails']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
