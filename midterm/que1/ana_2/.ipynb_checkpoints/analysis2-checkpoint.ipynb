{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 2\n",
    "\n",
    "#### Who were the people with the most emails?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the modules we need.\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import SoupStrainer\n",
    "import datetime\n",
    "from glob import glob\n",
    "import json\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import string\n",
    "import sys\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Path to the raw data.\n",
    "raw_data_path = os.path.expanduser(\"~/midterm/data/enron/maildir\")\n",
    "print(raw_data_path)\n",
    "\n",
    "# Path to the preprocessed data file (may or may not exist).\n",
    "preprocessed_data_path = os.path.expanduser(\"~/midterm/data/enron/preprocessed_analysis2.json\")\n",
    "print(preprocessed_data_path)\n",
    "\n",
    "# Check to see if the file is already there.\n",
    "def have_preprocessed_data():\n",
    "    return os.path.isfile(preprocessed_data_path)\n",
    "\n",
    "print(\"Preprocessed data? \" + str(have_preprocessed_data()))\n",
    "    \n",
    "# Make sure the stopwords corpus is available.\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the home directories in the Enron mail dump.\n",
    "def get_enron_home_dirs():\n",
    "    \n",
    "    # Save the working directory (for later restoration).\n",
    "    saved_path = os.getcwd()\n",
    "    print(saved_path)\n",
    "\n",
    "    # Get the paths to the data files.\n",
    "    # Use the contents of the directory as a way to get the usernames.\n",
    "    os.chdir(raw_data_path)\n",
    "    result = glob('*')\n",
    "\n",
    "    # Restore the working directory.\n",
    "    os.chdir(saved_path)\n",
    "    print(os.getcwd())\n",
    "\n",
    "    print(\"found \" + str(len(result)) + \" home directories:\")\n",
    "    print(result[0:50])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many items of email does each user have in their mail directory?\n",
    "\n",
    "# Create the mapping from a user to the number of email items they have.\n",
    "def create_user_email_list():\n",
    "    result = []\n",
    "\n",
    "    enron_home_dirs = get_enron_home_dirs()\n",
    "    for u in enron_home_dirs:\n",
    "        home_path = os.path.join(raw_data_path, u)\n",
    "        #print(home_path)\n",
    "    \n",
    "        # Save the current working directory.\n",
    "        saved_wd = os.getcwd()\n",
    "    \n",
    "        os.chdir(home_path)\n",
    "        user_emails = glob(\"**/**\")\n",
    "        result.append({'user': u, 'emails': len(user_emails)})\n",
    "    \n",
    "        #print(\"{user} had {count} emails\".format(user = u, count = len(user_emails)))\n",
    "    \n",
    "        # Restore the current working directory.\n",
    "        os.chdir(saved_wd)\n",
    "    \n",
    "    return result\n",
    "    \n",
    "# Restore from a preprocessed file.\n",
    "def restore_user_email_list():\n",
    "    print(\"Restoring from: \" + preprocessed_data_path)\n",
    "\n",
    "    result = []\n",
    "    with open(preprocessed_data_path, 'rt') as f:\n",
    "        try:\n",
    "            result = json.load(f)\n",
    "        except ValueError:\n",
    "            result = []\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Save data as a preprocessed file.\n",
    "def save_user_email_list(list_to_save):\n",
    "    print(\"Saving user email list to: \" + preprocessed_data_path)\n",
    "    with open(preprocessed_data_path, 'wt') as f:\n",
    "        json.dump(list_to_save, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Does the preprocessed file exist?\n",
    "user_email_list = []\n",
    "if have_preprocessed_data():\n",
    "    user_email_list = restore_user_email_list()\n",
    "else:\n",
    "    user_email_list = create_user_email_list()\n",
    "    save_user_email_list(user_email_list)\n",
    "\n",
    "# Sort in descending order so the most prolific emailers are at the top.\n",
    "user_email_list.sort(key=lambda x: x['emails'], reverse=True)\n",
    "print(user_email_list[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pretty-print the 50 users with the most emails.\n",
    "for i in user_email_list[0:50]:\n",
    "    print(\"{name} had {count} emails\".format(name=i['user'], count=i['emails']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
